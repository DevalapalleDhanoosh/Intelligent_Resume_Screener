{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98eb0041-d16e-40ad-bbcf-7d055b64fb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c55a50f-82ba-4885-9f5e-075ff8965f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Resumes Object\n",
    "resumes = df[['Category', 'Resume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4327e0f8-e182-47e0-91a3-728fcd1b46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interim structure\n",
    "resumes.to_json(r'C:/Users/lenovo/OneDrive/Desktop/IntelligentResumeScreenerProjectFolder/parsed_data/raw_text.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f0b9956-0773-4010-a80b-e2085841a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume parsing complete. Output saved to: C:/Users/lenovo/OneDrive/Desktop/IntelligentResumeScreenerProjectFolder/parsed_data\\raw_text.json\n"
     ]
    }
   ],
   "source": [
    "# Resume Parsing & NLP Extraction\n",
    "import re\n",
    "import spacy\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load spaCy English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Predefined list of skills and education keywords\n",
    "skills_list = ['python', 'sql', 'tableau', 'power bi', 'machine learning']\n",
    "edu_keywords = ['bachelor', 'bsc', 'msc', 'phd', 'computer science']\n",
    "\n",
    "# Function to parse a single resume's text\n",
    "def parse_resume(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract possible year phrases\n",
    "    year_matches = re.findall(r'(\\d+(?:\\.\\d+)?)\\+?\\s*(?:years?|yrs?)', text.lower())\n",
    "    experience = None\n",
    "\n",
    "    if year_matches:\n",
    "        # Convert to float and take max (handles '3', '2.5', etc.)\n",
    "        experience = max([float(x) for x in year_matches])\n",
    "    elif re.search(r'\\bfresher\\b|\\bno experience\\b|0\\s*(?:years?|yrs?)', text.lower()):\n",
    "        experience = 0.0\n",
    "\n",
    "    return {\n",
    "        'name': doc.ents[0].text if doc.ents else None,\n",
    "        'email': re.search(r'[\\w.-]+@[\\w.-]+', text).group(0) if re.search(r'[\\w.-]+@[\\w.-]+', text) else None,\n",
    "        'phone': re.search(r'\\+?\\d[\\d\\s\\-]{8,}\\d', text).group(0) if re.search(r'\\+?\\d[\\d\\s\\-]{8,}\\d', text) else None,\n",
    "        'skills': list({s for s in skills_list if s in text.lower()}),\n",
    "        'education': list({e for e in edu_keywords if e in text.lower()}),\n",
    "        'experience': experience  # Could be None, 0.0, or float\n",
    "    }\n",
    "\n",
    "\n",
    "# Parse all resumes from DataFrame\n",
    "parsed = []\n",
    "for _, row in resumes.iterrows():\n",
    "    entry = parse_resume(row['Resume'])\n",
    "    entry['category'] = row['Category']  # Add resume category (e.g., HR, DS)\n",
    "    parsed.append(entry)\n",
    "\n",
    "# Define output path\n",
    "output_dir = r'C:/Users/lenovo/OneDrive/Desktop/IntelligentResumeScreenerProjectFolder/parsed_data'\n",
    "output_file = os.path.join(output_dir, 'raw_text.json')\n",
    "\n",
    "# Ensure the folder exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save parsed results as JSON\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(parsed, f, indent=4)\n",
    "\n",
    "print(\"Resume parsing complete. Output saved to:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a218d940-a595-4981-b2b0-427a4e4f9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_dict = {\n",
    "    \"HR\": \"\"\"\n",
    "        Job Title: Human Resources Executive\n",
    "\n",
    "        Responsibilities:\n",
    "        - Recruit and onboard new employees\n",
    "        - Handle employee relations\n",
    "        - Maintain HR documentation and compliance\n",
    "        - Assist in performance reviews and policy enforcement\n",
    "\n",
    "        Required Skills:\n",
    "        - Communication\n",
    "        - HR policies\n",
    "        - Employee engagement\n",
    "        - MS Office\n",
    "    \"\"\",\n",
    "\n",
    "    \"Data Science\": \"\"\"\n",
    "        Job Title: Data Scientist\n",
    "\n",
    "        Responsibilities:\n",
    "        - Build machine learning models\n",
    "        - Analyze large datasets\n",
    "        - Perform feature engineering and data wrangling\n",
    "        - Present findings to stakeholders\n",
    "\n",
    "        Required Skills:\n",
    "        - Python\n",
    "        - SQL\n",
    "        - Machine Learning\n",
    "        - Data Analysis\n",
    "        - Tableau / Power BI\n",
    "    \"\"\",\n",
    "\n",
    "    # Add more categories if applicable\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22477dd6-0b8f-4b94-ad80-eb596d8c05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Match Score Function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_match_score(resume_skills_text, jd_text):\n",
    "    if not resume_skills_text or not jd_text:\n",
    "        return 0.0  # Return 0 if either is missing\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform([jd_text.lower(), resume_skills_text.lower()])\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "    return round(similarity * 100, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b00c39e1-6409-4b35-a870-23535bc141e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Matching to Each Resume\n",
    "import json\n",
    "\n",
    "# Load parsed resumes if not already in memory\n",
    "with open(\"C:/Users/lenovo/OneDrive/Desktop/IntelligentResumeScreenerProjectFolder/parsed_data/raw_text.json\", \"r\") as f:\n",
    "    parsed_resumes = json.load(f)\n",
    "\n",
    "# Compute match score\n",
    "for resume in parsed_resumes:\n",
    "    jd_text = jd_dict.get(resume.get('category', ''), \"\")\n",
    "    resume_skills_text = ' '.join(resume.get('skills', []))\n",
    "    resume['match_score'] = compute_match_score(resume_skills_text, jd_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb986ed-e5ea-48db-89cc-82106eaea1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD matching complete. Ranked resumes saved to: C:/Users/lenovo/OneDrive/Desktop/IntelligentResumeScreenerProjectFolder/parsed_data/ranked_resumes.json\n"
     ]
    }
   ],
   "source": [
    "# Save Ranked Results\n",
    "# Sort by match_score descending\n",
    "parsed_resumes = sorted(parsed_resumes, key=lambda x: x.get('match_score', 0), reverse=True)\n",
    "\n",
    "# Save to ranked_resumes.json\n",
    "output_path = r\"C:/Users/lenovo/OneDrive/Desktop/IntelligentResumeScreenerProjectFolder/parsed_data/ranked_resumes.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(parsed_resumes, f, indent=4)\n",
    "\n",
    "print(\"JD matching complete. Ranked resumes saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f18ff1c-5dd6-4c96-9375-7ec5790e770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-pythonNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading mysql_connector_python-9.3.0-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Downloading mysql_connector_python-9.3.0-cp312-cp312-win_amd64.whl (16.4 MB)\n",
      "   ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/16.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/16.4 MB 2.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.6/16.4 MB 2.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.4/16.4 MB 3.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 3.1/16.4 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.5/16.4 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 5.5/16.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 7.1/16.4 MB 4.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 8.4/16.4 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.4/16.4 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.2/16.4 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.3/16.4 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 13.1/16.4 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.9/16.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.5/16.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.4/16.4 MB 5.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "513ece61-a0ec-46b4-b45f-51cebc021f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Connect to MySQL from Python\n",
    "import mysql.connector\n",
    "\n",
    "# Replace with your actual credentials\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'Dhanoosh@1',\n",
    "    'database': 'resume_screener'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ee58f77-5ef8-494e-91c1-56fe2706190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All resume data inserted into MySQL database.\n"
     ]
    }
   ],
   "source": [
    "# Load and Insert Ranked Resume Data\n",
    "import json\n",
    "import mysql.connector\n",
    "\n",
    "# Load parsed & ranked data\n",
    "with open(r\"C:/Users/lenovo/OneDrive/Desktop/IntelligentResumeScreenerProjectFolder/parsed_data/ranked_resumes.json\", \"r\") as f:\n",
    "    resumes = json.load(f)\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert each resume into the MySQL table\n",
    "for r in resumes:\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO resumes (name, email, phone, skills, education, experience, category, match_score)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        r.get('name'),\n",
    "        r.get('email'),\n",
    "        r.get('phone'),\n",
    "        ', '.join(r.get('skills') or []),\n",
    "        ', '.join(r.get('education') or []),\n",
    "        r.get('experience'),\n",
    "        r.get('category'),\n",
    "        r.get('match_score')\n",
    "    ))\n",
    "\n",
    "# Commit & close\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"All resume data inserted into MySQL database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d47c831d-8e39-482a-995a-b3e79dde71a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sql', 36.34)\n",
      "('Tableau', 36.34)\n",
      "('Sql', 36.34)\n",
      "('Tableau', 36.34)\n",
      "('Sql', 36.34)\n"
     ]
    }
   ],
   "source": [
    "# Query Examples in Python\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name, match_score FROM resumes ORDER BY match_score DESC LIMIT 5\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de70d1a7-c840-44a1-8440-c5e8824877f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidates with Python & Power BI\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT name, skills, match_score \n",
    "    FROM resumes \n",
    "    WHERE skills LIKE '%python%' AND skills LIKE '%power bi%' \n",
    "    ORDER BY match_score DESC\n",
    "\"\"\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e850e697-6e69-4717-b04c-5abbf6a51f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl (18.5 MB)\n",
      "   ---------------------------------------- 0.0/18.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.5 MB 1.9 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.0/18.5 MB 1.7 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.6/18.5 MB 2.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.6/18.5 MB 2.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 3.7/18.5 MB 3.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 4.5/18.5 MB 3.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 5.2/18.5 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.6/18.5 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 7.6/18.5 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 9.2/18.5 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 10.7/18.5 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 12.3/18.5 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 13.1/18.5 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 14.9/18.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.5/18.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.4/18.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.5/18.5 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Installing collected packages: docx2txt, pymupdf\n",
      "\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   -------------------- ------------------- 1/2 [pymupdf]\n",
      "   ---------------------------------------- 2/2 [pymupdf]\n",
      "\n",
      "Successfully installed docx2txt-0.9 pymupdf-1.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf58037-6264-4552-8b49-704b219342e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
